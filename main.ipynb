{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install category_encoders\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_distances , cosine_similarity\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(\"player-data-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Unwanted features\n",
    "\n",
    "###### These features will later be used as filters, so we stored them in a seperate dataset. \n",
    "###### For example, the user will be able to set a maximum budget, age or wage when searching for the perfect fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to remove\n",
    "columns_to_remove = [\n",
    "    'image', 'description', 'real_face', 'club_logo', 'country_flag', 'version', 'full_name', \n",
    "    'club_id', 'club_league_id', 'country_id', 'country_league_id', \n",
    "    'club_kit_number', 'country_kit_number', 'club_league_name', 'club_rating', 'country_position', \n",
    "    'club_contract_valid_until', 'club_name', 'potential', 'value', 'wage', 'overall_rating',  \n",
    "    'international_reputation', 'release_clause', 'body_type', 'specialities', 'club_position', \n",
    "    'club_joined', 'country_name', 'country_league_name', 'country_rating'\n",
    "]\n",
    "\n",
    "# Ensure 'player_id' is included for the filters DataFrame\n",
    "filter_columns = ['player_id'] + columns_to_remove\n",
    "\n",
    "# Create the filters DataFrame\n",
    "filters = players[filter_columns].copy()\n",
    "\n",
    "# Drop the filter columns from the original players DataFrame\n",
    "players = players.drop(columns=columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'country_rating', 'country_league_name', 'club_joined', 'club_position',\n",
    "    'specialities', 'body_type', 'image', 'description', 'real_face', \n",
    "    'club_logo', 'country_flag', 'version', 'full_name', 'club_id', \"country_id\",\n",
    "    'club_league_id', 'country_league_id', 'club_kit_number', \n",
    "    'country_kit_number', 'club_rating', 'country_position', \n",
    "    'international_reputation'\n",
    "]\n",
    "\n",
    "filters = filters.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.lower().replace('€', '').replace(',', '')  # Remove euro sign and commas\n",
    "        if 'k' in value:\n",
    "            return float(value.replace('k', '').strip()) * 1000  # Multiply by 1000 for 'k'\n",
    "        elif 'm' in value:\n",
    "            return float(value.replace('m', '').strip()) * 1000000  # Multiply by 1,000,000 for 'm'\n",
    "        else:\n",
    "            return float(value)  # If no 'k' or 'm', just convert the number directly\n",
    "    return value  # If already a number, return it unchanged\n",
    "\n",
    "# Apply this function to the 'value', 'wage', and 'release_clause' columns\n",
    "for column in ['value', 'wage', 'release_clause']:\n",
    "    filters[column] = filters[column].apply(convert_to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating the Age Feature\n",
    "\n",
    "To make the dataset more suitable for analysis and modeling, we replaced the `date_of_birth` column with a new column called `age`.\n",
    "\n",
    "While `date_of_birth` contains important information, it is stored in a **date format** that is not directly useful for most machine learning algorithms. Dates must typically be transformed into a numerical representation, and without context (like the current year), they are hard for models to interpret effectively.\n",
    "\n",
    "By calculating the **age of each player at the time of data collection**, we converted this temporal data into a **single, meaningful numeric value**. This simplifies the feature and allows the model to learn patterns based on age — a highly relevant factor in player performance, development potential, and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Convert 'dob' to datetime format\n",
    "players['dob'] = pd.to_datetime(players['dob'], errors='coerce')\n",
    "\n",
    "# Calculate age based on today's date\n",
    "today = datetime.today()\n",
    "players['age'] = players['dob'].apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)))\n",
    "\n",
    "# Drop the original 'dob' column if not needed\n",
    "players = players.drop(columns=['dob'])\n",
    "\n",
    "# Display the dataset with the new 'age' column\n",
    "print(players[['name', 'age']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure player_id exists in both DataFrames\n",
    "assert 'player_id' in players.columns and 'player_id' in filters.columns, \"player_id must be in both DataFrames\"\n",
    "\n",
    "# Merge the age column into filters\n",
    "filters = filters.merge(players[['player_id', 'age']], on='player_id', how='left')\n",
    "\n",
    "# Drop age from players\n",
    "players = players.drop(columns=['age'])\n",
    "\n",
    "# Check results\n",
    "print(\"✅ 'age' successfully moved to filters.\")\n",
    "print(\"filters columns:\", filters.columns)\n",
    "print(\"players columns:\", players.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. One-Hot Encoding the Positions Feature\n",
    "\n",
    "The `positions` column in our dataset often includes **multiple positions per player**, such as `\"CM, CDM\"` or `\"RW, ST\"`. These entries represent the different roles a player is capable of performing on the field.\n",
    "\n",
    "To make this information usable for machine learning models, we applied **one-hot encoding** to this feature. This technique transforms each unique position into a binary feature (1 if the player plays in that position, 0 otherwise).\n",
    "\n",
    "By doing so, we created a set of new columns — one for each individual position — enabling the model to understand positional versatility. This is especially important in the context of **player flexibility**, which can be a critical indicator of value or role suitability in tactical systems.\n",
    "\n",
    "This transformation ensures that players who can operate in multiple roles contribute more richly to the model, without losing any semantic detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import pandas as pd\n",
    "\n",
    "# Define all possible positions in FIFA\n",
    "fifa_positions = ['GK', 'CB', 'LB', 'RB', 'LWB', 'RWB', \n",
    "                  'CDM', 'CM', 'CAM', 'LM', 'RM', \n",
    "                  'LW', 'RW', 'ST', 'CF']\n",
    "\n",
    "# Create new columns for each position and set them to 0\n",
    "for pos in fifa_positions:\n",
    "    players[pos] = players['positions'].apply(lambda x: 1 if pos in x else 0)\n",
    "\n",
    "# Drop the original 'positions' column as it's now redundant\n",
    "players = players.drop(columns=['positions'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(players.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Four Main Playstyles\n",
    "\n",
    "To manage the high cardinality of the `play_styles` column, we took a dimensionality reduction approach rather than applying one-hot encoding.\n",
    "\n",
    "Originally, this column contained **around 50 unique playstyles**, each describing a specific attribute or behavior of a player. One-hot encoding these values would have dramatically increased the number of features in our dataset, adding significant noise and computational complexity, especially given that many of these playstyles have only marginal influence on model performance.\n",
    "\n",
    "Instead, we consolidated them into **four broader, technically meaningful categories**, each representing a set of similar playstyles. This approach preserved important semantic information while drastically reducing dimensionality, resulting in **only four new binary features**. Each new column corresponds to one of the grouped playstyle categories and indicates whether a player fits within that group.\n",
    "\n",
    "This method strikes a balance between data richness and model simplicity, contributing to more efficient learning and better generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define playstyle categories\n",
    "categories = {\n",
    "    \"Playmakers_Technicians\": [\"Incisive Pass\", \"Tiki Taka\", \"Press Proven\", \"Pinged Pass\", \"First Touch\", \"Flair\", \"Trivela\", \"Technical\", \"Solid Player\"],\n",
    "    \"Clinical_Finishers_GoalPoachers\": [\"Finesse Shot\", \"Power Shot\", \"Poacher\", \"Chip Shot\", \"Trivela\", \"Aerial\", \"Acrobatic\", \"Quick Step\"],\n",
    "    \"Defensive_Walls_Destroyers\": [\"Bruiser\", \"Intercept\", \"Slide Tackle\", \"Block\", \"Press Proven\", \"Relentless\", \"Aerial\"],\n",
    "    \"Physical_Speed_Based_Players\": [\"Rapid\", \"Quick Step\", \"Speedster\", \"Power Header\", \"Aerial\", \"Relentless\"]\n",
    "    \n",
    "}\n",
    "\n",
    "# Function to assign binary values for each category\n",
    "def assign_binary_columns(play_styles):\n",
    "    if pd.isna(play_styles): \n",
    "        return {key: 0 for key in categories}\n",
    "    \n",
    "    styles = set(play_styles.split(\",\"))  # Convert to a set for quick lookup\n",
    "    \n",
    "    return {category: int(any(style.strip() in keywords for style in styles)) for category, keywords in categories.items()}\n",
    "\n",
    "# Apply function to the 'Play_Style' column in your existing `players` dataset\n",
    "binary_columns = players[\"play_styles\"].apply(assign_binary_columns).apply(pd.Series)\n",
    "\n",
    "# Merge binary columns into the `players` DataFrame\n",
    "players = pd.concat([players, binary_columns], axis=1)\n",
    "\n",
    "players = players.drop(columns=['play_styles'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One-Hot Encoding Work Rate and Preferred Foot Feature\n",
    "\n",
    "To prepare the dataset for machine learning algorithms, we performed one-hot encoding on two categorical features: `preferred_foot` and `work_rate`.\n",
    "\n",
    "- The `preferred_foot` column, which originally had values `\"Right\"` or `\"Left\"`, was converted to binary format: Right → 1 and Left → 0.\n",
    "\n",
    "- The `work_rate` column included combined values such as `\"High/Medium\"` to represent attacking and defensive work rates. We split this feature into two separate columns: `Attacking Work Rate` and `Defensive Work Rate`.\n",
    "\n",
    "- Each new column was then numerically encoded using the following mapping: `Low = 0`, `Medium = 1`, and `High = 2`.\n",
    "\n",
    "Finally, we dropped the original `work_rate` column after encoding, as its information was now captured in a machine-readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for 'preferred_foot'\n",
    "players['preferred_foot'] = players['preferred_foot'].map({'Right': 1, 'Left': 0})\n",
    "\n",
    "# Split 'work_rate' into two new columns\n",
    "players[['Attacking Work Rate', 'Defensive Work Rate']] = players['work_rate'].str.split('/', expand=True)\n",
    "\n",
    "# Define mapping for work rate categories\n",
    "work_rate_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "\n",
    "# Apply mapping to the new columns\n",
    "players['Attacking Work Rate'] = players['Attacking Work Rate'].map(work_rate_mapping)\n",
    "players['Defensive Work Rate'] = players['Defensive Work Rate'].map(work_rate_mapping)\n",
    "\n",
    "# Drop the original 'work_rate' column\n",
    "players.drop(columns=['work_rate'], inplace=True)\n",
    "\n",
    "# Check result\n",
    "print(players[['preferred_foot', 'Attacking Work Rate', 'Defensive Work Rate']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Removing Goalkeeper Features and PlayStyles Column\n",
    "\n",
    "The dataset contains several columns related to **goalkeeper (GK) attributes**, such as `gk_reflexes` and `gk_diving`, which are not relevant to outfield players like attackers and midfielders. Including these features would introduce noise and reduce model accuracy for player roles unrelated to goalkeeping.\n",
    "\n",
    "To address this, we removed all columns that contain `'gk'` in their names. This ensures the model is trained only on attributes meaningful to the playing positions under study.\n",
    "\n",
    "Additionally, we dropped the `play_styles` column, which was already processed and represented in the dataset through four newly engineered features (as discussed earlier). Keeping it would have introduced redundancy.\n",
    "\n",
    "This cleanup step streamlines the dataset and ensures that only relevant and non-redundant features are passed to the machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'play_styles' column and any column that contains 'gk' in its name\n",
    "players = players.drop(columns=[col for col in players.columns if 'gk' in col.lower()] + ['play_styles'], errors='ignore')\n",
    "\n",
    "# Display remaining columns to verify\n",
    "print(players.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Position-Based Splitting of the Dataset\n",
    "\n",
    "To improve the accuracy and relevance of our player similarity model, we decided to split the main dataset into **smaller subsets based on player positions** (e.g., attackers, midfielders, defenders, goalkeepers).\n",
    "\n",
    "This approach allows us to train and analyze each group separately, as **different positions require different skill sets and performance indicators**. For example:\n",
    "- A forward’s similarity should be based on shooting, positioning, and pace.\n",
    "- A midfielder would be evaluated using passing, vision, and stamina.\n",
    "- A defender’s value comes from tackling, marking, and strength.\n",
    "\n",
    "By splitting the dataset, we can **customize the feature selection and similarity logic** for each role, which leads to more meaningful and position-specific comparisons between players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "center_backs = players[players['CB'] == 1]\n",
    "full_backs = players[(players['LB'] == 1) | (players['RB'] == 1) | (players['LWB'] == 1) | (players['RWB'] == 1)]\n",
    "defensive_mids = players[players['CDM'] == 1]\n",
    "midfielders = players[players['CM'] == 1]\n",
    "attacking_mids = players[players['CAM'] == 1| (players['CF'] == 1)]\n",
    "wingers = players[(players['LW'] == 1) | (players['RW'] == 1) ]\n",
    "strikers = players[(players['ST'] == 1) | (players['CF'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = {\n",
    "    'CAM': {\n",
    "        'dataset_path': 'attack_mid.pkl',\n",
    "        'features_path': 'attack_mid_features.pkl'\n",
    "    },\n",
    "    'LW': {\n",
    "        'dataset_path': 'wingers.pkl',\n",
    "        'features_path': 'wingers_features.pkl'\n",
    "    },\n",
    "    'RW': {\n",
    "        'dataset_path': 'wingers.pkl',\n",
    "        'features_path': 'wingers_features.pkl'\n",
    "    },\n",
    "    'ST': {\n",
    "        'dataset_path': 'strikers.pkl',\n",
    "        'features_path': 'strikers_features.pkl'\n",
    "    },\n",
    "    'CDM': {\n",
    "        'dataset_path': 'defensive_mids.pkl',\n",
    "        'features_path': 'defensive_mids_features.pkl'\n",
    "    },\n",
    "    'CM': {\n",
    "        'dataset_path': 'defensive_mids.pkl',\n",
    "        'features_path': 'defensive_mids_features.pkl'\n",
    "    },\n",
    "    'CB': {\n",
    "        'dataset_path': 'center_backs.pkl',\n",
    "        'features_path': 'center_backs_features.pkl'\n",
    "    },\n",
    "    'LB': {\n",
    "        'dataset_path': 'full_backs.pkl',\n",
    "        'features_path': 'full_backs_features.pkl'\n",
    "    },\n",
    "    'RB': {\n",
    "        'dataset_path': 'full_backs.pkl',\n",
    "        'features_path': 'full_backs_features.pkl'\n",
    "    }\n",
    "    # Add more as needed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defensive_mids.to_csv('defensive_mids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_players(input_name, top_n=10):\n",
    "    matches = players[players['name'].str.contains(input_name, case=False, na=False)]\n",
    "    \n",
    "    if matches.empty:\n",
    "        print(\"❌ No matching player found.\")\n",
    "        return\n",
    "    \n",
    "    for _, row in matches.iterrows():\n",
    "        player_name = row['name']\n",
    "        player_id = row['player_id']\n",
    "        \n",
    "        # Detect position from one-hot columns\n",
    "        position_cols = [col for col in players.columns if col in position_data]\n",
    "        player_position = None\n",
    "        for pos in position_cols:\n",
    "            if row[pos] == 1:\n",
    "                player_position = pos\n",
    "                break\n",
    "        \n",
    "        if not player_position:\n",
    "            print(f\"⚠️ No known position found for {player_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n🔍 Similar players to: {player_name} ({player_position})\")\n",
    "\n",
    "        if player_position not in position_data:\n",
    "            print(f\"⚠️ No data defined for position: {player_position}\")\n",
    "            continue\n",
    "\n",
    "        # Load dataset and features\n",
    "        dataset = pd.read_pickle(position_data[player_position]['dataset_path'])\n",
    "        with open(position_data[player_position]['features_path'], \"rb\") as f:\n",
    "            features = pickle.load(f)\n",
    "\n",
    "        if player_id not in dataset['player_id'].values:\n",
    "            print(\"❌ Player not found in position-specific dataset.\")\n",
    "            continue\n",
    "\n",
    "        # Prepare data\n",
    "        df = dataset[['name', 'player_id'] + features].dropna()\n",
    "        names = df['name']\n",
    "        X = df[features]\n",
    "\n",
    "        # PCA pipeline\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        pca = PCA(n_components=0.95)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "        # Cosine similarity\n",
    "        cosine_sim = cosine_distances(X_pca)\n",
    "        idx = df[df['player_id'] == player_id].index[0]\n",
    "        sim_scores = sorted(list(enumerate(cosine_sim[idx])), key=lambda x: x[1])[1:top_n+1]\n",
    "\n",
    "        for i, (sim_idx, dist) in enumerate(sim_scores, 1):\n",
    "            print(f\"{i}. {names.iloc[sim_idx]} — Similarity Score: {1 - dist:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def find_similar_players(input_name, top_n=10, max_wage=None, max_age=None, max_value=None, \n",
    "                          max_release_clause=None, club_name=None, club_league_name=None, \n",
    "                          country_name=None, min_overall_rating=None):\n",
    "    matches = players[players['name'].str.contains(input_name, case=False, na=False)]\n",
    "    \n",
    "    if matches.empty:\n",
    "        print(\"❌ No matching player found.\")\n",
    "        return\n",
    "    \n",
    "    for _, row in matches.iterrows():\n",
    "        player_name = row['name']\n",
    "        player_id = row['player_id']\n",
    "        \n",
    "        # Detect position from one-hot columns\n",
    "        position_cols = [col for col in players.columns if col in position_data]\n",
    "        player_position = None\n",
    "        for pos in position_cols:\n",
    "            if row[pos] == 1:\n",
    "                player_position = pos\n",
    "                break\n",
    "        \n",
    "        if not player_position:\n",
    "            print(f\"⚠️ No known position found for {player_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n🔍 Similar players to: {player_name} ({player_position})\")\n",
    "\n",
    "        if player_position not in position_data:\n",
    "            print(f\"⚠️ No data defined for position: {player_position}\")\n",
    "            continue\n",
    "\n",
    "        # Load dataset and features\n",
    "        dataset = pd.read_pickle(position_data[player_position]['dataset_path'])\n",
    "        with open(position_data[player_position]['features_path'], \"rb\") as f:\n",
    "            features = pickle.load(f)\n",
    "\n",
    "        if player_id not in dataset['player_id'].values:\n",
    "            print(\"❌ Player not found in position-specific dataset.\")\n",
    "            continue\n",
    "\n",
    "        # Prepare data\n",
    "        df = dataset[['name', 'player_id'] + features].dropna()\n",
    "        names = df['name']\n",
    "        X = df[features]\n",
    "\n",
    "        # PCA pipeline\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        pca = PCA(n_components=0.95)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "        # Cosine similarity setup\n",
    "        idx = df[df['player_id'] == player_id].index[0]\n",
    "        input_vector = X_pca[idx]\n",
    "\n",
    "        eligible_players = []\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            sim_id = row['player_id']\n",
    "            if sim_id == player_id:\n",
    "                continue  # Skip the input player\n",
    "\n",
    "            # Apply filters\n",
    "            filter_conditions = True\n",
    "\n",
    "            if max_wage is not None:\n",
    "                wage = filters.loc[filters['player_id'] == sim_id, 'wage'].values\n",
    "                if wage.size > 0 and wage[0] > max_wage:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if max_value is not None:\n",
    "                value = filters.loc[filters['player_id'] == sim_id, 'value'].values\n",
    "                if value.size > 0 and value[0] > max_value:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if max_release_clause is not None:\n",
    "                clause = filters.loc[filters['player_id'] == sim_id, 'release_clause'].values\n",
    "                if clause.size > 0 and clause[0] > max_release_clause:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if max_age is not None:\n",
    "                age = filters.loc[filters['player_id'] == sim_id, 'age'].values\n",
    "                if age.size > 0 and int(age[0]) > int(max_age):\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if club_name is not None:\n",
    "                club = filters.loc[filters['player_id'] == sim_id, 'club_name'].values\n",
    "                if club.size > 0 and club[0] != club_name:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if club_league_name is not None:\n",
    "                league = filters.loc[filters['player_id'] == sim_id, 'club_league_name'].values\n",
    "                if league.size > 0 and league[0] != club_league_name:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if country_name is not None:\n",
    "                country = filters.loc[filters['player_id'] == sim_id, 'country_name'].values\n",
    "                if country.size > 0 and country[0] != country_name:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if min_overall_rating is not None:\n",
    "                rating = filters.loc[filters['player_id'] == sim_id, 'overall_rating'].values\n",
    "                if rating.size > 0 and rating[0] < min_overall_rating:\n",
    "                    filter_conditions = False\n",
    "\n",
    "            if filter_conditions:\n",
    "                # Get the correct index for X_pca\n",
    "                pca_idx = df.index.get_loc(i)  # This maps the `i` to the correct index in `X_pca`\n",
    "                candidate_vector = X_pca[pca_idx]  # Access the PCA vector using the correct index\n",
    "                similarity_score = 1 - cosine_distances([input_vector], [candidate_vector])[0][0]\n",
    "                eligible_players.append((row['name'], similarity_score))\n",
    "\n",
    "        # Sort by similarity and show top N\n",
    "        eligible_players.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if eligible_players:\n",
    "            print(\"\\nTop eligible players:\")\n",
    "            for i, (name, score) in enumerate(eligible_players[:top_n], 1):\n",
    "                print(f\"{i}. {name} — Similarity Score: {score:.4f}\")\n",
    "        else:\n",
    "            print(\"⚠️ No players meet the filter criteria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_players(\"declan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
